{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Text Generation Training and Experiments\n",
    "\n",
    "11/20/2017 - Experiments to train the full end to end adversarial text generation framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1,2,3\n",
      "Use CUDA:True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import sklearn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from dataset import SpamDataset\n",
    "from discriminator import MultinomialNBDiscriminator\n",
    "from autoencoder import SpamSeq2SeqAutoencoder\n",
    "from seq2seq.model import Seq2Seq, Seq2SeqAutoencoder\n",
    "\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1,2,3\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print \"Use CUDA:\" + str(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 30_trunc_50_adv_50_auto_0_easy_dancin\n"
     ]
    }
   ],
   "source": [
    "adversarial_weights = [.5, .8, .9, .95]\n",
    "\n",
    "truncation_len=30\n",
    "adversarial_weight = adversarial_weights[0] # The weight to give to \"fooling\" the discriminator\n",
    "autoencoder_weight = 1 - adversarial_weight\n",
    "easy_dataset = False\n",
    "\n",
    "experiment_name = \"%d_trunc_%d_adv_%d_auto_%d_easy_dancin\" % (truncation_len, adversarial_weight*100, autoencoder_weight*100, easy_dataset)\n",
    "print \"Experiment: \" + experiment_name    \n",
    "# Initialize logging.\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filename='log/%s' % (experiment_name),\n",
    "    filemode='w'\n",
    ")\n",
    "\n",
    "# define a new Handler to log to console as well\n",
    "console = logging.StreamHandler()\n",
    "# optional, set the logging leveld\n",
    "console.setLevel(logging.INFO)\n",
    "# set a format which is the same for console use\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "# tell the handler to use this format\n",
    "console.setFormatter(formatter)\n",
    "# add the handler to the root logger\n",
    "logging.getLogger('').addHandler(console)\n",
    "\n",
    "# If True, use the easy spam dataset composed of lower confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

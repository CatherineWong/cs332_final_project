{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Text Generation Training and Experiments\n",
    "\n",
    "11/20/2017 - Experiments to train the full end to end adversarial text generation framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1,2,3\n",
      "Use CUDA:True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import sklearn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from dataset import SpamDataset\n",
    "from discriminator import MultinomialNBDiscriminator\n",
    "from autoencoder import SpamSeq2SeqAutoencoder\n",
    "from seq2seq.model import Seq2Seq, Seq2SeqAutoencoder\n",
    "\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1,2,3\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print \"Use CUDA:\" + str(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions.\n",
    "def get_dataset_minibatch(examples, iter_ind, batch_size):\n",
    "    \"\"\"\n",
    "    Iterator over the dataset split and get autoencoder minibatches.\n",
    "    \"\"\"\n",
    "    minibatch = examples[iter_ind:iter_ind+batch_size]\n",
    "\n",
    "    # Create the Pytorch variables.\n",
    "    input_lines = Variable(torch.LongTensor(np.fliplr(minibatch).copy())).cuda() # Reverse the input lines.\n",
    "    output_lines = Variable(torch.LongTensor(minibatch)).cuda()\n",
    "    return input_lines, output_lines\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 30_trunc_50_adv_50_auto_0_easy_dancin\n"
     ]
    }
   ],
   "source": [
    "adversarial_weights = [.5, .8, .9, .95]\n",
    "\n",
    "truncation_len=30\n",
    "adversarial_weight = adversarial_weights[0] # The weight to give to \"fooling\" the discriminator\n",
    "autoencoder_weight = 1 - adversarial_weight\n",
    "easy_dataset = False # Whether to use lower confidence spam.\n",
    "\n",
    "epochs = 1\n",
    "batch_size=50\n",
    "\n",
    "experiment_name = \"%d_trunc_%d_adv_%d_auto_%d_easy_dancin\" % (truncation_len, adversarial_weight*100, autoencoder_weight*100, easy_dataset)\n",
    "print \"Experiment: \" + experiment_name    \n",
    "# Initialize logging.\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filename='log/%s' % (experiment_name),\n",
    "    filemode='w'\n",
    ")\n",
    "\n",
    "# define a new Handler to log to console as well\n",
    "console = logging.StreamHandler()\n",
    "# optional, set the logging leveld\n",
    "console.setLevel(logging.INFO)\n",
    "# set a format which is the same for console use\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "# tell the handler to use this format\n",
    "console.setFormatter(formatter)\n",
    "# add the handler to the root logger\n",
    "logging.getLogger('').addHandler(console)\n",
    "\n",
    "# If True, use the easy spam dataset composed of lower confidence scores.\n",
    "if easy_dataset:\n",
    "    raise Exception(\"Not yet implemented: easy_datset\")\n",
    "else:\n",
    "    spam_dataset = SpamDataset(truncation_len=truncation_len, encoded_files=['encoded_spam.txt'])\n",
    "\n",
    "    \n",
    "### Initialize the various models.###\n",
    "\n",
    "    \n",
    "### Training loop.###\n",
    "examples, _ = spam_dataset.examples(split=\"train\", shuffled=True)\n",
    "num_examples, max_len = examples.shape\n",
    "for epoch in xrange(epochs):\n",
    "    losses = []\n",
    "    for iter_ind in xrange(0, num_examples, batch_size):\n",
    "        # Get a minibatch.\n",
    "        input_lines_src, output_lines_src = get_dataset_minibatch(examples, iter_ind, batch_size)\n",
    "        \n",
    "        \n",
    "        # Run a training step.\n",
    "        \n",
    "        # Calculate rewards.\n",
    "        \n",
    "        # Update the model.\n",
    "        \n",
    "        # Monitor loss.\n",
    "        \n",
    "        # Print a sample.\n",
    "         if iter_ind % print_samples == 0:\n",
    "            # Print samples.\n",
    "            word_probs = model.decode(decoder_logit).data.cpu().numpy().argmax(axis=-1)\n",
    "            output_lines_trg = input_lines_src.data.cpu().numpy()\n",
    "            for sentence_pred, sentence_real in zip(word_probs[:5], output_lines_trg[:5]):\n",
    "                decoded_real = dataset.vocab_encoder.decode_numpy(sentence_real[::-1])\n",
    "                decoded_pred = dataset.vocab_encoder.decode_numpy(sentence_pred)\n",
    "\n",
    "                logging.info('===============================================')\n",
    "                logging.info(\"REAL: \" + decoded_real)\n",
    "                logging.info(\"PREDICTED: \" + decoded_pred)\n",
    "                logging.info('===============================================')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
